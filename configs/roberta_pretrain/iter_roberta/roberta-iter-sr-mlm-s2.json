{
    "bert_name": "iter_roberta_sr_mlm_s",
    "reader_name": "wiki_pre_train_ent_mp",
    "model_name_or_path": "/data/volume1/roberta-base",
    "output_dir": "roberta_iter_sr_mlm_s_2",
    "predict_dir": "roberta_iter_sr_mlm_s_2",
    "predict_file": "/data/volume2/wiki_en_dev_10k_wk5_0.7_0.8_0.1_0.3_0.0_0.0_0.0_59.json",
    "max_seq_length": 512,
    "train_batch_size": 32,
    "predict_batch_size": 8,
    "learning_rate": 5e-5,
    "num_train_epochs": 16,
    "max_steps": 80000,
    "gradient_accumulation_steps": 4,
    "num_workers": 4,
    "fp16_opt_level": "O2",
    "per_eval_step": 2000,
    "per_save_step": 2000,
    "logging_step": 5,
    "adam_betas": "(0.9, 0.98)",
    "adam_epsilon": 1e-6,
    "warmup_proportion": 0.05,
    "max_grad_norm": -1,
    "input_file_list": "file_list_wk5_7_9_join.json",
    "fp16": true,
    "correct_bias": true,
    "add_lm": true,
    "query_dropout": 0.1,
    "sr_query_dropout": 0.1,
    "lm_query_dropout": 0.1,
    "z_step": 2
}